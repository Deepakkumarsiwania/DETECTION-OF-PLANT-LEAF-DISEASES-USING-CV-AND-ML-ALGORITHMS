# -*- coding: utf-8 -*-
"""MTP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lG899droWvGfFWvDJmpPRY2iEzsDOeLp
"""

import numpy as np
import cv2
import glob
import os
import matplotlib.pyplot as plt
import string
from mlxtend.plotting import plot_decision_regions
from mpl_toolkits.mplot3d import Axes3D
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.utils.multiclass import unique_labels
from sklearn import metrics
from sklearn.svm import SVC
dim = 100

!pip install imutils

from imutils import paths
import cv2

!unzip /content/drive/MyDrive/Tomato.zip -d MTP

image_path=list(paths.list_images("/content/MTP/dataset"))

dataset=os.listdir("/content/MTP/dataset")

test_address=["/content/MTP/dataset/val/Bacterial_spot","/content/MTP/dataset/val/Early_blight","/content/MTP/dataset/val/Late_blight","/content/MTP/dataset/val/Leaf_Mold","/content/MTP/dataset/val/Septoria_leaf_spot","/content/MTP/dataset/val/Spider_mites Two-spotted_spider_mite","/content/MTP/dataset/val/Target_Spot","/content/MTP/dataset/val/Tomato_Yellow_Leaf_Curl_Virus","/content/MTP/dataset/val/Tomato_mosaic_virus","/content/MTP/dataset/val/healthy"]

train_address=["/content/MTP/dataset/train/Bacterial_spot","/content/MTP/dataset/train/Early_blight","/content/MTP/dataset/train/Late_blight","/content/MTP/dataset/train/Leaf_Mold","/content/MTP/dataset/train/Septoria_leaf_spot","/content/MTP/dataset/train/Spider_mites Two-spotted_spider_mite","/content/MTP/dataset/train/Target_Spot","/content/MTP/dataset/train/Tomato_Yellow_Leaf_Curl_Virus","/content/MTP/dataset/train/Tomato_mosaic_virus","/content/MTP/dataset/train/healthy"]

# @title Default title text
import os

# Define the paths for the train and test datasets
train_base_dir = '/content/MTP/dataset/train'
test_base_dir = '/content/MTP/dataset/val'

# List of class names to keep
class_names_to_keep = [
    "Late_blight", "Tomato_mosaic_virus", "healthy",
    "Septoria_leaf_spot", "Bacterial_spot", "Tomato_Yellow_Leaf_Curl_Virus"
]

# Create lists to store the file paths for train and test images
train_image_paths = []
test_image_paths = []

# Populate the train and test image paths based on the specified classes
for class_name in class_names_to_keep:
    train_image_paths.extend([os.path.join(train_base_dir, class_name, filename) for filename in os.listdir(os.path.join(train_base_dir, class_name))])
    test_image_paths.extend([os.path.join(test_base_dir, class_name, filename) for filename in os.listdir(os.path.join(test_base_dir, class_name))])

import cv2
import os

# Define the paths for the original and processed datasets
original_dataset_dir = '/content/MTP/dataset/train'  # Replace with your training dataset path
original_test_dataset_dir = '/content/MTP/dataset/val'  # Replace with your test dataset path
processed_dataset_dir = '/content/MTP/dataset/train_histogram_equalized'
processed_test_dataset_dir = '/content/MTP/dataset/val_histogram_equalized'

# List of class names (assuming each subdirectory corresponds to a class)
classes_for_equalization = ["Late_blight", "Tomato_mosaic_virus", "healthy", "Septoria_leaf_spot", "Bacterial_spot", "Tomato_Yellow_Leaf_Curl_Virus"]

# Create a function to apply histogram equalization to specific classes in a dataset
def apply_histogram_equalization_for_classes(original_dir, processed_dir, classes):
    # Create the processed dataset directory if it doesn't exist
    os.makedirs(processed_dir, exist_ok=True)

    # Iterate through the specified class names for equalization
    for class_name in classes:
        class_dir = os.path.join(original_dir, class_name)
        processed_class_dir = os.path.join(processed_dir, class_name)

        # Create the processed class directory if it doesn't exist
        os.makedirs(processed_class_dir, exist_ok=True)

        # Iterate through images in the class directory
        for filename in os.listdir(class_dir):
            # Load the image
            image_path = os.path.join(class_dir, filename)
            image = cv2.imread(image_path, cv2.IMREAD_COLOR)

            # Apply histogram equalization
            if image is not None:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                equalized_image = cv2.equalizeHist(image)

                # Save the processed image
                processed_image_path = os.path.join(processed_class_dir, filename)
                cv2.imwrite(processed_image_path, equalized_image)

# Apply histogram equalization to the training dataset for specified classes
apply_histogram_equalization_for_classes(original_dataset_dir, processed_dataset_dir, classes_for_equalization)
print("Histogram equalization applied to the training dataset for specified classes.")

# Apply histogram equalization to the test dataset for specified classes
apply_histogram_equalization_for_classes(original_test_dataset_dir, processed_test_dataset_dir, classes_for_equalization)
print("Histogram equalization applied to the test dataset for specified classes.")

# import matplotlib.pyplot as plt
# import random

# # Show 4 random segmented images
# num_images_to_show = 4
# plt.figure(figsize=(12, 8))

# for i in range(num_images_to_show):
#     # Select a random image index
#     random_index = random.randint(0, len(segmented_images) - 1)
#     image = segmented_images[random_index]

#     # Display the image
#     plt.subplot(1, num_images_to_show, i + 1)
#     plt.imshow(cv2.cvtColor(image, cv2.COLOR_LAB2RGB))  # Convert back to RGB for display
#     plt.axis('off')

# plt.show()

import cv2
import os
import random
import matplotlib.pyplot as plt

# Define the directory for the processed dataset
processed_dataset_dir = '/content/MTP/dataset/train_histogram_equalized'  # Replace with your processed dataset path

# Define the number of random images to display
num_images_to_display = 5  # You can change this number as needed

# Create a figure and axis for displaying the images
fig, axes = plt.subplots(1, num_images_to_display, figsize=(15, 3))

# Get a list of class subdirectories
class_subdirs = [os.path.join(processed_dataset_dir, class_name) for class_name in classes_for_equalization]

for i in range(num_images_to_display):
    # Randomly select a class subdirectory
    random_class_dir = random.choice(class_subdirs)

    # Randomly select an image from the class subdirectory
    random_image_filename = random.choice(os.listdir(random_class_dir))
    random_image_path = os.path.join(random_class_dir, random_image_filename)

    # Load and display the image
    random_image = cv2.imread(random_image_path, cv2.IMREAD_GRAYSCALE)
    axes[i].imshow(random_image, cmap='gray')
    class_name = os.path.basename(random_class_dir)
    axes[i].set_title(class_name)
    axes[i].axis('off')

plt.show()

# print(train_image_paths[0])
# print(len(test_image_paths))

image=train_image_paths[0]

"""**for full datset**"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import random

# Function to segment the image using k-means clustering
# Function to segment the image using k-means clustering
def segment_kmeans(image, target_label):
    pixel_values = image.reshape((-1, 3))
    pixel_values = np.float32(pixel_values)

    k = 2  # Number of clusters (you may adjust this)

    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
    _, labels, center = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)

    target_mask = (labels == target_label).astype(np.uint8)
    target_mask = target_mask.reshape(image.shape[:2])

    target_part = cv2.bitwise_and(image, image, mask=target_mask)
    return target_part

# (Remains the same as provided earlier)

# Directory containing your images
directory_path = "/content/MTP/dataset/train_histogram_equalized"  # Change this directory path

# Collect all image file paths in the directory and its subdirectories
all_image_files = []
for root, dirs, files in os.walk(directory_path):
    for file in files:
        if file.lower().endswith(('jpg', 'png')):
            image_path = os.path.join(root, file)
            all_image_files.append(image_path)

# Select 5 random image paths from the collected list
selected_image_files = random.sample(all_image_files, 5)

# Process and display the selected images
for image_path in selected_image_files:
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Process image using k-means for target_label = 1
    target_label = 1
    target_part_1 = segment_kmeans(image, target_label)

    # Process image using k-means for target_label = 0
    target_label = 0
    target_part_0 = segment_kmeans(image, target_label)

    # Display the segmented parts for both labels
    plt.figure(figsize=(15, 5))
    plt.subplot(131), plt.imshow(image), plt.title('Original Image')
    plt.subplot(132), plt.imshow(target_part_1), plt.title('Target Label 1')
    plt.subplot(133), plt.imshow(target_part_0), plt.title('Target Label 0')
    plt.suptitle(f'Image: {os.path.basename(image_path)}')
    plt.show()

# Process and display the selected images
for image_path in selected_image_files:
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    print(image.shape)

    # Process image using k-means for target_label = 1
    target_label = 1
    target_part_1 = segment_kmeans(image, target_label)

    # Process image using k-means for target_label = 0
    target_label = 0
    target_part_0 = segment_kmeans(image, target_label)

    # Display the segmented parts for both labels
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 3, 1)
    plt.imshow(image)
    plt.title('Original Image')
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(target_part_1)
    plt.title('Segment (Label 1)')
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(target_part_0)
    plt.title('Segment (Label 0)')
    plt.axis('off')

    plt.suptitle(f'Image: {os.path.basename(image_path)}', fontsize=14)
    plt.tight_layout()
    plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import random

# Function to segment the image using k-means clustering
def segment_kmeans(image, target_label):
    pixel_values = image.reshape((-1, 3))
    pixel_values = np.float32(pixel_values)

    k = 3  # Number of clusters (you may adjust this)

    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
    _, labels, center = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)

    target_mask = (labels == target_label).astype(np.uint8)
    target_mask = target_mask.reshape(image.shape[:2])

    target_part = cv2.bitwise_and(image, image, mask=target_mask)
    return target_part, target_mask

# Directory containing your images
directory_path = "/content/MTP/dataset/train_histogram_equalized"  # Change this directory path

# Collect all image file paths in the directory and its subdirectories
all_image_files = []
for root, dirs, files in os.walk(directory_path):
    for file in files:
        if file.lower().endswith(('jpg', 'png')):
            image_path = os.path.join(root, file)
            all_image_files.append(image_path)

# Select 5 random image paths from the collected list
selected_image_files = random.sample(all_image_files, 5)

# Process and display the selected images
for image_path in selected_image_files:
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Process image using k-means for target_label = 1
    target_label = 1
    target_part_1, mask_1 = segment_kmeans(image, target_label)

    # Process image using k-means for target_label = 0
    target_label = 0
    target_part_0, mask_0 = segment_kmeans(image, target_label)

    # Find contours for segmented parts
    contours_1, _ = cv2.findContours(mask_1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours_0, _ = cv2.findContours(mask_0, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Draw contours on the original image
    cv2.drawContours(image, contours_1, -1, (0, 255, 0), 2)
    cv2.drawContours(image, contours_0, -1, (0, 0, 255), 2)

    # Display the original image with contours
    plt.figure(figsize=(8, 6))
    plt.imshow(image)
    plt.title(f'Image: {os.path.basename(image_path)} with Contours')
    plt.axis('off')
    plt.show()

map = {
    "Late_blight":0, "Tomato_mosaic_virus":1, "healthy":1,
    "Septoria_leaf_spot":3, "Bacterial_spot":4, "Tomato_Yellow_Leaf_Curl_Virus":5
}

print(all_image_files[5].split("/"))

"""**SVM** **IMPLEMETATION**"""

image= cv2.imread('all_image_files[0]')

import cv2
import numpy as np
import matplotlib.pyplot as plt
import pywt
import os
import random
from tqdm import tqdm

# Function to segment the image using k-means clustering
# ... (previous code remains the same)
def dwt_feature_extraction(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    coeffs = pywt.dwt2(gray, 'haar')
    cA, (cH, cV, cD) = coeffs

    # Calculate various statistical measures on wavelet coefficients
    features = [
        np.mean(cA), np.mean(cH), np.mean(cV), np.mean(cD),
        np.std(cA), np.std(cH), np.std(cV), np.std(cD),
        np.median(cA), np.median(cH), np.median(cV), np.median(cD),
        np.max(cA), np.max(cH), np.max(cV), np.max(cD),
        np.min(cA), np.min(cH), np.min(cV), np.min(cD),
        np.sum(cA), np.sum(cH), np.sum(cV), np.sum(cD)
    ]

    return features

feature_array=(dwt_feature_extraction(target_part_1))

# feature_array_2d = np.array([feature_array])
print(feature_array)

# # Reshape feature_array_2d into a (256, 256) array
# import numpy as np

# # Assuming feature_array_2d is your array of size 24
# feature_array_2d = np.array([feature_array])

# # Reshape the array into a (256, 256) shape with zero padding
# feature_array_reshaped = np.pad(feature_array_2d, ((0, 256 - feature_array_2d.shape[0]), (0, 256 - feature_array_2d.shape[1])), mode='constant')

# # Now feature_array_reshaped is a (256, 256) array with zero padding

# print(feature_array_reshaped)

import cv2
import numpy as np
import matplotlib.pyplot as plt
import pywt
import os
import random
from tqdm import tqdm

# Function to segment the image using k-means clustering
# ... (previous code remains the same)

# Function to perform DWT and extract features
def dwt_feature_extraction(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    coeffs = pywt.dwt2(gray, 'haar')
    cA, (cH, cV, cD) = coeffs

    features = [np.mean(cA), np.mean(cH), np.mean(cV), np.mean(cD)]
    return features
# Directory containing your images
directory_path = "/content/MTP/dataset/train_histogram_equalized"  # Change this directory path

# Collect all image file paths in the directory and its subdirectories
all_image_files = []
for root, dirs, files in os.walk(directory_path):
    for file in files:
        if file.lower().endswith(('jpg', 'png')):
            image_path = os.path.join(root, file)
            all_image_files.append(image_path)



X=[]
y=[]
# Extract features using DWT for the selected images
for image_path in tqdm(all_image_files):
    image = cv2.imread(image_path)

    # Process image using k-means for target_label = 1
    target_label = 1
    target_part_1, mask_1 = segment_kmeans(image, target_label)

    # Process image using k-means for target_label = 0
    target_label = 0
    target_part_0, mask_0 = segment_kmeans(image, target_label)
    label=image_path.split("/")[5]
    y.append(map[label])
    # Feature extraction using DWT on the segmented parts
    features_1 = dwt_feature_extraction(target_part_1)
    # feature_array_2d = np.array([features_1])
    # feature_array_reshaped = np.pad(feature_array_2d, ((0, 256 - feature_array_2d.shape[0]), (0, 256 - feature_array_2d.shape[1])), mode='constant')
# def dwt_feature_with_glcm(feature_array_2d):
#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#     coeffs = pywt.dwt2(gray, 'haar')
#     cA, (_, _, _) = coeffs

#     # Convert the image to an unsigned integer type
#     cA = cA.astype(np.uint8)

#     # GLCM on the approximate component (cA)
#     glcm = greycomatrix(cA, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256, symmetric=True, normed=True)

#     # Calculate properties from GLCM
#     contrast = greycoprops(glcm, 'contrast')
#     dissimilarity = greycoprops(glcm, 'dissimilarity')
#     homogeneity = greycoprops(glcm, 'homogeneity')
#     energy = greycoprops(glcm, 'energy')
#     correlation = greycoprops(glcm, 'correlation')

#     glcm_features = np.array([contrast, dissimilarity, homogeneity, energy, correlation]).flatten()
#     return glcm_features
# Now feature_array_reshaped is a (256, 256) array with zero padding

    # features_0 = dwt_feature_extraction(target_part_0)
    X.append(features_1)
    # Display the features extracted from DWT
    # print(f"Image: {os.path.basename(image_path)}")
    # print("Features for Target Label 1:", features_1)
    # print("Features for Target Label 0:", features_0)
    # print("-----------------------------------------")






    # Display the features extracted from DWT
    # print(f"Image: {os.path.basename(image_path)}")
    # print("Features for Target Label 1:", features_1)
    # print("Features for Target Label 0:", features_0)
    # print("-----------------------------------------")

# Import necessary libraries
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score


# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Standardize the features by removing the mean and scaling to unit variance
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Create an SVM model
svm_model = SVC(kernel='linear', C=5.0)

# Train the SVM model
svm_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = svm_model.predict(X_test)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy * 100:.2f}%')
from sklearn.metrics import precision_score, recall_score, f1_score

# Calculate precision
precision = precision_score(y_test, y_pred, average='weighted')

# Calculate recall
recall = recall_score(y_test, y_pred, average='weighted')

# Calculate F1-score
f1 = f1_score(y_test, y_pred, average='weighted')

# Print the results
print(f'Precision: {precision * 100:.2f}%')
print(f'Recall: {recall * 100:.2f}%')
print(f'F1-score: {f1 * 100:.2f}%')

import cv2
import numpy as np
import pywt
import os
import random
import matplotlib.pyplot as plt

# Function to segment the image using k-means clustering
# ... (previous code remains the same)

# Function to perform DWT and extract features as images
def dwt_feature_as_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    coeffs = pywt.dwt2(gray, 'haar')
    cA, (cH, cV, cD) = coeffs

    # Resize coefficients to the size of cA (approximate component)
    cH = cv2.resize(cH, (cA.shape[1], cA.shape[0]))
    cV = cv2.resize(cV, (cA.shape[1], cA.shape[0]))
    cD = cv2.resize(cD, (cA.shape[1], cA.shape[0]))

    # Normalize the coefficients to convert them to images
    cA = cv2.normalize(cA, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    cH = cv2.normalize(cH, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    cV = cv2.normalize(cV, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    cD = cv2.normalize(cD, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)

    # Create images of the DWT coefficients
    img_features = np.vstack((np.hstack((cA, cH)), np.hstack((cV, cD))))

    return img_features

# Directory containing your images
directory_path = "/content/MTP/dataset/train_histogram_equalized"  # Change this directory path

# Collect all image file paths in the directory and its subdirectories
all_image_files = []
for root, dirs, files in os.walk(directory_path):
    for file in files:
        if file.lower().endswith(('jpg', 'png')):
            image_path = os.path.join(root, file)
            all_image_files.append(image_path)

# Select 5 random image paths from the collected list
selected_image_files = random.sample(all_image_files, 5)

# Extract and display DWT features as images for the selected images
for image_path in selected_image_files:
    image = cv2.imread(image_path)

    print(image.shape)

    # Process image using k-means for target_label = 1
    target_label = 1
    target_part_1, mask_1 = segment_kmeans(image, target_label)

    # Process image using k-means for target_label = 0
    target_label = 0
    target_part_0, mask_0 = segment_kmeans(image, target_label)

    # Extract DWT features as images
    img_features_1 = dwt_feature_as_image(target_part_1)
    img_features_0 = dwt_feature_as_image(target_part_0)

    # Display the DWT features as images
    plt.figure(figsize=(8, 4))
    plt.subplot(121), plt.imshow(img_features_1, cmap='gray')
    plt.title('DWT Features (Target Label 1)')
    plt.axis('off')

    plt.subplot(122), plt.imshow(img_features_0, cmap='gray')
    plt.title('DWT Features (Target Label 0)')
    plt.axis('off')

    plt.suptitle(f'Image: {os.path.basename(image_path)}', fontsize=12)
    plt.tight_layout()
    plt.show()

# Directory containing your images
directory_path = "/content/MTP/dataset/train_histogram_equalized"  # Change this directory path

# List to store image features
image_features_list = []

# Collect all image file paths in the directory and its subdirectories
all_image_files = []
for root, dirs, files in os.walk(directory_path):
    for file in files:
        if file.lower().endswith(('jpg', 'png')):
            image_path = os.path.join(root, file)
            all_image_files.append(image_path)

# Iterate over all image files and extract DWT features
for image_path in all_image_files:
    # Load the image
    image = cv2.imread(image_path)
    # Extract DWT features as images
    img_features = dwt_feature_as_image(image)
    # Append the image features to the list
    image_features_list.append(img_features)

# Now image_features_list contains the DWT features for all images



import cv2
import numpy as np
import pywt
from skimage.feature import greycomatrix, greycoprops
from sklearn.decomposition import PCA
import os
import random
import matplotlib.pyplot as plt

# Function to segment the image using k-means clustering
# ... (previous code remains the same)

# Function to perform DWT and extract GLCM features
def dwt_feature_with_glcm(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    coeffs = pywt.dwt2(gray, 'haar')
    cA, (_, _, _) = coeffs

    # Convert the image to an unsigned integer type
    cA = cA.astype(np.uint8)

    # GLCM on the approximate component (cA)
    glcm = greycomatrix(cA, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256, symmetric=True, normed=True)

    # Calculate properties from GLCM
    contrast = greycoprops(glcm, 'contrast')
    dissimilarity = greycoprops(glcm, 'dissimilarity')
    homogeneity = greycoprops(glcm, 'homogeneity')
    energy = greycoprops(glcm, 'energy')
    correlation = greycoprops(glcm, 'correlation')

    glcm_features = np.array([contrast, dissimilarity, homogeneity, energy, correlation]).flatten()
    return glcm_features

# Directory containing your images
directory_path = "/content/MTP/dataset/train_histogram_equalized"  # Change this directory path

# List to store GLCM features for each image
glcm_features_list = []

# Collect all image file paths in the directory and its subdirectories
all_image_files = []
for root, dirs, files in os.walk(directory_path):
    for file in files:
        if file.lower().endswith(('jpg', 'png')):
            image_path = os.path.join(root, file)
            all_image_files.append(image_path)

# Iterate over all image files and extract GLCM features
for image_path in all_image_files:
    # Load the image
    image = cv2.imread(image_path)
    # Extract DWT features with GLCM
    glcm_features = dwt_feature_with_glcm(image)
    # Append the GLCM features to the list
    glcm_features_list.append(glcm_features)

# Now glcm_features_list contains the GLCM features for all images

"""**SIMPLE** **CNN**"""

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

from torchvision.datasets import ImageFolder

# Define the root directories of the train and validation datasets.
train_root_dir = '/content/MTP/dataset/train_histogram_equalized'
val_root_dir = '/content/MTP/dataset/val_histogram_equalized'

# Create the ImageFolder datasets for the train and validation sets.
train_dataset = ImageFolder(root=train_root_dir, transform= transforms.Compose([
    # transforms.Grayscale(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
]))
val_dataset = ImageFolder(root=val_root_dir, transform= transforms.Compose([
    # transforms.Grayscale(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
]))

train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
validation_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)

import torchvision.models as models
model = models.resnet18(pretrained=False, num_classes=6)

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

from PIL import Image

for epoch in range(10):
    for images, labels in train_dataloader:
        # Forward pass.
        # print(images.shape)
        outputs = model(images)

        # Compute the loss.
        loss = criterion(outputs, labels)
        # print(loss.item())
        # Backward pass.
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

# Evaluate the model on the validation set.
correct_predictions = 0
total_predictions = 0
with torch.no_grad():
    for images, labels in validation_dataloader:
        outputs = model(images)
        predictions = torch.argmax(outputs, dim=1)
        correct_predictions += (predictions == labels).sum().item()
        total_predictions += len(labels)
accuracy = correct_predictions / total_predictions
print(f'Validation accuracy: {accuracy:.4f}')